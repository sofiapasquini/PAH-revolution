{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unlike-alloy",
   "metadata": {},
   "source": [
    "## This is some rough pseudo code for algorithm ideas I have for my Master's research work.\n",
    "\n",
    "### Three main algorithms-rough structure/package implementation ideas for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effective-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant packages\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score #(?)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-effort",
   "metadata": {},
   "source": [
    "# Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the data\n",
    "#assuming a set of spectra can be represented in the form of a pd dataframe\n",
    "    #where each row is a spectrum, each column is a flux value.\n",
    "\n",
    "df = #load data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply some kind of standardization across the fluxes?\n",
    "scaler = StandardScaler\n",
    "df = scaler.fit_transform(df)\n",
    "\n",
    "X = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-custody",
   "metadata": {},
   "source": [
    "# Algorithm 1: \"Basic\" Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-command",
   "metadata": {},
   "source": [
    "A basic agglomerative clustering algorithm.\n",
    "\n",
    "- determine the optimal number of clusters using either a silhouette score or dendrogram visualization\n",
    "- deploy optimal clustering algorithm\n",
    "- apply a PCA decomp to retrieve feature space\n",
    "- visualize results\n",
    "- analyze key features of average spectra in each cluster- groupby, plots of each averaged spectra, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the appropriate number of clusters to use\n",
    "n_cluster_range = [4,6,8,10,15] #a range of clusters to explore\n",
    "\n",
    "for n_cluster in n_cluster_range:\n",
    "    # initialize the clusterer with n_clusters and a random_seed for reproducability\n",
    "    clusterer = KMeans(n_clusters = n_clusters) #or AgglomerativeClustering(n_clusters, random_seed)\n",
    "    # generate cluster labels\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "    \n",
    "    #calculate silhouette scores\n",
    "    \n",
    "    #generate silhouette plot\n",
    "        # see code in CS4414B/Assignment_Week11-Clean\n",
    "        \n",
    "\n",
    "optimal_clusters = # analyze silhouette plot for the optimal number of clusters.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA on data in order to retreive parameter-space dimensions\n",
    "pca = PCA(n_components = 2) # use 2 from Ameek's paper- could also experiment with others...\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "#apply clustering algorithm with chosen number of clusters and plot results\n",
    "\n",
    "#initialize the figure\n",
    "fig, axs = plt.subplots(1,1)\n",
    "\n",
    "clusterer = #the chosen clustering algorithm\n",
    "cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "#plot in pc space, color-code by cluster\n",
    "for i in range(optimal_clusters):\n",
    "    color = cm.nipy_spectral(float(i) / optimal_clusters)\n",
    "    plt.scatter(X_pca[cluster_labels==i, 0], X_pca[cluster_labels==i, 1], \n",
    "                label='Cluster %i' % (i+1))\n",
    "\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.title('PCA-transformed plot for %i clusters' % n_clusters)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-network",
   "metadata": {},
   "source": [
    "# Algorithm 2 : \"Enhanced Clustering 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-skill",
   "metadata": {},
   "source": [
    "Agglomerative clustering algorithm except the output is passed as input to KMeans clustering to serve as initial centroid positions.\n",
    "- determine the optimal number of clusters using either a silhouette score or dendrogram visualization\n",
    "- deploy agglomerative clustering with optimal number of clusters\n",
    "- deploy KMeans clustering with K=optimal_number_of_cluster and initialize positions at output from agglomerative clustering algorithm\n",
    "- sanity check- (re-?)calculate silhouette score for clusters and compare with agglomerative partitions\n",
    "- apply a PCA decomp to retrieve feature space\n",
    "- visualize results\n",
    "- analyze key features of average spectra in each cluster- groupby, plots of each averaged spectra, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-shannon",
   "metadata": {},
   "source": [
    "# Algorithm 3: \"Enhanced Clustering 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-seattle",
   "metadata": {},
   "source": [
    "Agglomerative clustering based on input from a computed RF dissimilarity score (Euclidean analog)\n",
    "- determine the optimal number of clusters using either a silhouette score or dendrogram visualization\n",
    "- generate a synthetic \"dataset\" based on marginal distributions of real data, apply labels to both sets\n",
    "- train RFClassifier on both sets (real=1)\n",
    "- calculate similarity score->dissimilarity score\n",
    "- deploy agglomerative clustering with dissimilarity score as input (??have to look more into this specific step/implementation)\n",
    "- \u0010apply a PCA decomp to retrieve feature space\n",
    "- visualize results\n",
    "- analyze key features of average spectra in each cluster- groupby, plots of each averaged spectra, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-belize",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
